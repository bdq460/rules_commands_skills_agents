#!/usr/bin/env node
/**
 * Research Assistant Agent
 * æ™ºèƒ½ç ”ç©¶åŠ©æ‰‹ - ååŠ©è¿›è¡ŒæŠ€æœ¯è°ƒç ”ã€ä¿¡æ¯æ”¶é›†å’ŒçŸ¥è¯†æ•´ç†
 *
 * è¿™æ˜¯ä¸€ä¸ªæ ‡å‡†çš„ LLM Agentï¼Œå¯ä»¥ï¼š
 * 1. æ‰§è¡Œå¤šæ­¥éª¤ç ”ç©¶ä»»åŠ¡
 * 2. æ”¶é›†å’Œæ•´ç†ä¿¡æ¯
 * 3. ç”Ÿæˆç ”ç©¶æŠ¥å‘Š
 * 4. æä¾›å†³ç­–å»ºè®®
 *
 * æ”¯æŒå¤šç§å¤§æ¨¡å‹ï¼šOpenAIã€GLMã€Claudeã€Qwenã€DeepSeek ç­‰
 * ä½¿ç”¨ JSON é…ç½®æ–‡ä»¶ç®¡ç† LLM è®¾ç½®
 */

import * as fs from "fs/promises";
import { OpenAI } from "openai";
import * as path from "path";
import {
    ConfigManager,
    type LLMConfig,
    type ProviderConfig,
    configManager,
} from "./config/llm-config";

// ============================================================================
// ç±»å‹å®šä¹‰
// ============================================================================

interface ResearchTask {
    id: string;
    topic: string;
    questions: string[];
    depth: "overview" | "detailed" | "comprehensive";
    outputFormat: "summary" | "report" | "comparison" | "decision-matrix";
}

interface ResearchFinding {
    question: string;
    answer: string;
    sources: string[];
    confidence: "high" | "medium" | "low";
}

interface ResearchReport {
    task: ResearchTask;
    findings: ResearchFinding[];
    summary: string;
    recommendations?: string[];
    createdAt: Date;
    executionStats?: ExecutionStats;
}

/**
 * æ‰§è¡Œç»Ÿè®¡ä¿¡æ¯
 */
interface ExecutionStats {
    /** æ€»æ‰§è¡Œæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰ */
    totalTimeMs: number;
    /** å„é—®é¢˜æ‰§è¡Œæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰ */
    questionTimesMs: number[];
    /** æ€»ç»“ç”Ÿæˆæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰ */
    summaryTimeMs: number;
    /** æ€»æ¶ˆè€— token æ•° */
    totalTokens: number;
    /** æ€»è¯·æ±‚æ¬¡æ•° */
    totalRequests: number;
    /** å¼€å§‹æ—¶é—´ */
    startedAt: Date;
    /** ç»“æŸæ—¶é—´ */
    completedAt: Date;
}

// ============================================================================
// æ ¸å¿ƒç±»
// ============================================================================

export class ResearchAssistant {
    private client: OpenAI;
    private provider: ProviderConfig;
    private model: string;
    private maxTokens: number;
    private temperature: number;
    private totalTokens: number = 0; // æ€»æ¶ˆè€— token æ•°
    private totalRequests: number = 0; // æ€»è¯·æ±‚æ¬¡æ•°

    constructor(
        apiKey?: string,
        providerName?: string,
        model?: string,
        baseURL?: string
    ) {
        // è·å–å½“å‰æ¿€æ´»çš„æä¾›å•†é…ç½®
        this.provider = configManager.getActiveProvider();

        // å¦‚æœæŒ‡å®šäº†ç‰¹å®šæä¾›å•†ï¼Œåˆ‡æ¢åˆ°è¯¥æä¾›å•†
        if (providerName) {
            const config = configManager.getConfig();
            if (config.providers[providerName]) {
                this.provider = config.providers[providerName];
            } else {
                throw new Error(`æœªçŸ¥çš„æä¾›å•†: ${providerName}`);
            }
        }

        // ç¡®å®šæ¨¡å‹
        this.model = model || this.provider.model;

        // ç¡®å®š API Key
        const key = apiKey || this.provider.apiKey;
        if (!key || key.startsWith("${")) {
            throw new Error(
                `æœªæ‰¾åˆ° API Keyã€‚è¯·åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½® ${this.provider.name} çš„ apiKeyï¼Œæˆ–è®¾ç½®å¯¹åº”çš„ç¯å¢ƒå˜é‡`
            );
        }

        // ç¡®å®š Base URL
        const url = baseURL || this.provider.baseURL;

        // è·å–è®¾ç½®
        const settings = configManager.getConfig().settings;
        this.maxTokens = settings.maxTokens;
        this.temperature = settings.temperature;

        // åˆå§‹åŒ–å®¢æˆ·ç«¯
        this.client = new OpenAI({
            apiKey: key,
            baseURL: url,
        });

        console.log(`ğŸ¤– ä½¿ç”¨æ¨¡å‹: ${this.provider.name} (${this.model})`);
    }

    /**
     * æ‰§è¡Œç ”ç©¶ä»»åŠ¡
     */
    async conductResearch(task: ResearchTask): Promise<ResearchReport> {
        const startedAt = new Date();
        console.log(`ğŸ” å¼€å§‹ç ”ç©¶: ${task.topic}`);
        console.log(`   æ·±åº¦: ${task.depth}, æ ¼å¼: ${task.outputFormat}`);
        console.log(`   å¼€å§‹æ—¶é—´: ${startedAt.toLocaleString()}`);

        const findings: ResearchFinding[] = [];
        const questionTimesMs: number[] = [];

        // å¹¶è¡Œå›ç­”æ‰€æœ‰é—®é¢˜ï¼ˆå¸¦å¹¶å‘æ§åˆ¶ï¼‰
        const concurrencyLimit = 5; // æœ€å¤šåŒæ—¶3ä¸ªè¯·æ±‚
        console.log(`\nğŸ“ å¼€å§‹å¹¶è¡Œç ”ç©¶ ${task.questions.length} ä¸ªé—®é¢˜ (å¹¶å‘é™åˆ¶: ${concurrencyLimit})`);

        const processQuestion = async (question: string, index: number): Promise<ResearchFinding> => {
            const questionStart = Date.now();
            console.log(`   [${index + 1}/${task.questions.length}] ${question.substring(0, 50)}...`);
            const finding = await this.researchQuestion(question, task);
            const questionTime = Date.now() - questionStart;
            questionTimesMs[index] = questionTime;
            console.log(`   âœ… [${index + 1}] å®Œæˆ (ç½®ä¿¡åº¦: ${finding.confidence}, è€—æ—¶: ${this.formatDuration(questionTime)})`);
            return finding;
        };

        // åˆ†æ‰¹å¹¶è¡Œå¤„ç†
        for (let i = 0; i < task.questions.length; i += concurrencyLimit) {
            const batch = task.questions.slice(i, i + concurrencyLimit);
            const batchFindings = await Promise.all(
                batch.map((q, idx) => processQuestion(q, i + idx))
            );
            findings.push(...batchFindings);
        }

        // ç”Ÿæˆæ€»ç»“
        console.log(`\nğŸ“Š å¼€å§‹ç”Ÿæˆç ”ç©¶æ€»ç»“...`);
        const summaryStart = Date.now();
        const summary = await this.generateSummary(task, findings);
        const summaryTimeMs = Date.now() - summaryStart;
        console.log(`   âœ… æ€»ç»“ç”Ÿæˆå®Œæˆ (è€—æ—¶: ${this.formatDuration(summaryTimeMs)})`);

        // ç”Ÿæˆå»ºè®®ï¼ˆå¦‚æœéœ€è¦ï¼‰
        const recommendations = await this.generateRecommendations(task, findings);

        // è®¡ç®—æ‰§è¡Œç»Ÿè®¡
        const completedAt = new Date();
        const totalTimeMs = completedAt.getTime() - startedAt.getTime();

        const executionStats: ExecutionStats = {
            totalTimeMs,
            questionTimesMs,
            summaryTimeMs,
            totalTokens: this.totalTokens,
            totalRequests: this.totalRequests,
            startedAt,
            completedAt,
        };

        const report: ResearchReport = {
            task,
            findings,
            summary,
            recommendations,
            createdAt: new Date(),
            executionStats,
        };

        return report;
    }

    /**
     * æ ¼å¼åŒ–æ—¶é•¿
     */
    private formatDuration(ms: number): string {
        if (ms < 1000) {
            return `${ms}ms`;
        }
        return `${(ms / 1000).toFixed(2)}s`;
    }

    /**
     * ç ”ç©¶å•ä¸ªé—®é¢˜
     */
    private async researchQuestion(
        question: string,
        task: ResearchTask
    ): Promise<ResearchFinding> {
        const prompt = this.buildResearchPrompt(question, task);

        const response = await this.client.chat.completions.create({
            model: this.model,
            messages: [
                {
                    role: "system",
                    content: this.getSystemPrompt(task.depth),
                },
                {
                    role: "user",
                    content: prompt,
                },
            ],
            max_tokens: this.maxTokens,
            temperature: this.temperature,
        });

        // ç»Ÿè®¡ token ä½¿ç”¨
        this.totalRequests++;
        if (response.usage) {
            this.totalTokens += response.usage.total_tokens || 0;
        }

        const content = response.choices[0]?.message?.content || "";
        return this.parseFinding(question, content);
    }

    /**
     * æ„å»ºç ”ç©¶æç¤ºè¯
     */
    private buildResearchPrompt(question: string, task: ResearchTask): string {
        const depthInstructions = {
            overview: "æä¾›é«˜å±‚æ¬¡çš„æ¦‚è§ˆï¼Œæ¶µç›–ä¸»è¦è§‚ç‚¹å’Œå…³é”®ä¿¡æ¯ã€‚",
            detailed: "æä¾›è¯¦ç»†çš„åˆ†æï¼ŒåŒ…æ‹¬å…·ä½“æ•°æ®ã€æŠ€æœ¯ç»†èŠ‚å’Œå®ç°æ–¹å¼ã€‚",
            comprehensive:
                "æä¾›å…¨é¢çš„æ·±åº¦ç ”ç©¶ï¼ŒåŒ…æ‹¬å†å²èƒŒæ™¯ã€æŠ€æœ¯ç»†èŠ‚ã€ä¼˜ç¼ºç‚¹åˆ†æã€æœ€ä½³å®è·µå’Œæ¡ˆä¾‹ç ”ç©¶ã€‚",
        };

        return `
ç ”ç©¶ä¸»é¢˜: ${task.topic}
ç ”ç©¶é—®é¢˜: ${question}

ç ”ç©¶æ·±åº¦è¦æ±‚: ${depthInstructions[task.depth]}

è¯·æä¾›:
1. ç›´æ¥å›ç­”é—®é¢˜çš„æ ¸å¿ƒå†…å®¹
2. ç›¸å…³çš„æŠ€æœ¯ç»†èŠ‚æˆ–æ•°æ®æ”¯æŒ
3. å¯èƒ½çš„æ¥æºæˆ–å‚è€ƒï¼ˆå¦‚æœæœ‰ï¼‰
4. å¯¹è¯¥ç­”æ¡ˆç½®ä¿¡åº¦çš„è‡ªæˆ‘è¯„ä¼°

è¯·ä»¥ç»“æ„åŒ–æ ¼å¼å›ç­”ï¼Œä¾¿äºåç»­æ•´ç†ã€‚
    `.trim();
    }

    /**
     * è·å–ç³»ç»Ÿæç¤ºè¯
     */
    private getSystemPrompt(depth: string): string {
        return `
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æŠ€æœ¯ç ”ç©¶ä¸“å®¶ï¼Œæ“…é•¿æ·±å…¥åˆ†ææŠ€æœ¯ä¸»é¢˜å¹¶æä¾›å‡†ç¡®ã€å®¢è§‚çš„ç ”ç©¶ç»“æœã€‚

ä½ çš„ç‰¹ç‚¹:
- å›ç­”å‡†ç¡®ã€å®¢è§‚ï¼ŒåŸºäºäº‹å®
- æŠ€æœ¯ç»†èŠ‚ä¸°å¯Œï¼Œä½†è¡¨è¾¾æ¸…æ™°
- æ‰¿è®¤ä¸ç¡®å®šæ€§ï¼Œä¸ç¼–é€ ä¿¡æ¯
- æä¾›æœ‰è§åœ°çš„åˆ†æå’Œè§‚ç‚¹

ç ”ç©¶æ·±åº¦: ${depth}
    `.trim();
    }

    /**
     * è§£æç ”ç©¶å‘ç°
     */
    private parseFinding(question: string, content: string): ResearchFinding {
        // ç®€å•çš„ç½®ä¿¡åº¦åˆ¤æ–­
        let confidence: "high" | "medium" | "low" = "medium";
        if (content.includes("ç¡®å®š") || content.includes("æ˜ç¡®")) {
            confidence = "high";
        } else if (content.includes("å¯èƒ½") || content.includes("ä¸ç¡®å®š")) {
            confidence = "low";
        }

        // æå–æ¥æºï¼ˆç®€å•çš„å¯å‘å¼æ–¹æ³•ï¼‰
        const sources: string[] = [];
        const sourceMatches = content.match(/æ¥æº[:ï¼š]\s*(.+)/g);
        if (sourceMatches) {
            sourceMatches.forEach((match) => {
                const source = match.replace(/æ¥æº[:ï¼š]\s*/, "").trim();
                if (source) sources.push(source);
            });
        }

        return {
            question,
            answer: content,
            sources,
            confidence,
        };
    }

    /**
     * ç”Ÿæˆç ”ç©¶æ€»ç»“
     */
    private async generateSummary(
        task: ResearchTask,
        findings: ResearchFinding[]
    ): Promise<string> {
        const findingsText = findings
            .map((f) => `Q: ${f.question}\nA: ${f.answer.substring(0, 500)}...`)
            .join("\n\n");

        const prompt = `
åŸºäºä»¥ä¸‹ç ”ç©¶å‘ç°ï¼Œç”Ÿæˆä¸€ä»½ç®€æ´çš„ç ”ç©¶æ€»ç»“ï¼š

ç ”ç©¶ä¸»é¢˜: ${task.topic}

ç ”ç©¶å‘ç°:
${findingsText}

è¯·ç”Ÿæˆ:
1. æ ¸å¿ƒå‘ç°ï¼ˆ3-5 ç‚¹ï¼‰
2. å…³é”®æ´å¯Ÿ
3. æ€»ä½“ç»“è®º
    `.trim();

        const response = await this.client.chat.completions.create({
            model: this.model,
            messages: [{ role: "user", content: prompt }],
            max_tokens: 1500,
            temperature: 0.3,
        });

        // ç»Ÿè®¡ token ä½¿ç”¨
        this.totalRequests++;
        if (response.usage) {
            this.totalTokens += response.usage.total_tokens || 0;
        }

        return response.choices[0]?.message?.content || "æ— æ³•ç”Ÿæˆæ€»ç»“";
    }

    /**
     * ç”Ÿæˆå»ºè®®
     */
    private async generateRecommendations(
        task: ResearchTask,
        findings: ResearchFinding[]
    ): Promise<string[] | undefined> {
        if (task.outputFormat !== "decision-matrix") {
            return undefined;
        }

        const prompt = `
åŸºäºä»¥ä¸‹ç ”ç©¶å‘ç°ï¼Œæä¾› 3-5 æ¡å…·ä½“çš„è¡ŒåŠ¨å»ºè®®æˆ–å†³ç­–å»ºè®®ï¼š

${findings.map((f) => `- ${f.question}: ${f.answer.substring(0, 300)}`).join("\n")}

å»ºè®®åº”è¯¥:
- å…·ä½“å¯è¡Œ
- åŸºäºç ”ç©¶å‘ç°
- è€ƒè™‘å®é™…åº”ç”¨åœºæ™¯
    `.trim();

        const response = await this.client.chat.completions.create({
            model: this.model,
            messages: [{ role: "user", content: prompt }],
            max_tokens: 1000,
            temperature: 0.4,
        });

        // ç»Ÿè®¡ token ä½¿ç”¨
        this.totalRequests++;
        if (response.usage) {
            this.totalTokens += response.usage.total_tokens || 0;
        }

        const content = response.choices[0]?.message?.content || "";
        return content
            .split("\n")
            .filter((line: string) => line.trim().match(/^\d+\.|^[-â€¢]/))
            .map((line: string) => line.replace(/^\d+\.\s*|^[-â€¢]\s*/, "").trim());
    }

    /**
     * æ ¼å¼åŒ–æŠ¥å‘Šä¸º Markdown
     */
    formatAsMarkdown(report: ResearchReport): string {
        const formatConfidence = (c: string) => {
            const icons = { high: "ğŸŸ¢", medium: "ğŸŸ¡", low: "ğŸ”´" };
            return `${icons[c as keyof typeof icons]} ${c}`;
        };

        let md = `# ç ”ç©¶æŠ¥å‘Š: ${report.task.topic}\n\n`;
        md += `**ç”Ÿæˆæ—¶é—´**: ${report.createdAt.toLocaleString()}\n`;
        md += `**ç ”ç©¶æ·±åº¦**: ${report.task.depth}\n\n`;

        md += `## æ‰§è¡Œæ‘˜è¦\n\n${report.summary}\n\n`;

        md += `## è¯¦ç»†å‘ç°\n\n`;
        report.findings.forEach((finding, index) => {
            md += `### ${index + 1}. ${finding.question}\n\n`;
            md += `${finding.answer}\n\n`;
            md += `**ç½®ä¿¡åº¦**: ${formatConfidence(finding.confidence)}\n`;
            if (finding.sources.length > 0) {
                md += `**å‚è€ƒæ¥æº**: ${finding.sources.join(", ")}\n`;
            }
            md += `\n---\n\n`;
        });

        if (report.recommendations && report.recommendations.length > 0) {
            md += `## å»ºè®®\n\n`;
            report.recommendations.forEach((rec, index) => {
                md += `${index + 1}. ${rec}\n`;
            });
            md += `\n`;
        }

        // æ·»åŠ æ‰§è¡Œç»Ÿè®¡
        if (report.executionStats) {
            md += this.formatExecutionStats(report.executionStats);
        }

        return md;
    }

    /**
     * æ ¼å¼åŒ–æ‰§è¡Œç»Ÿè®¡ä¿¡æ¯
     */
    private formatExecutionStats(stats: ExecutionStats): string {
        const avgQuestionTime = stats.questionTimesMs.length > 0
            ? stats.questionTimesMs.reduce((a, b) => a + b, 0) / stats.questionTimesMs.length
            : 0;

        let md = `## æ‰§è¡Œæ€»ç»“\n\n`;
        md += `| æŒ‡æ ‡ | æ•°å€¼ |\n`;
        md += `|------|------|\n`;
        md += `| **æ€»æ‰§è¡Œæ—¶é—´** | ${this.formatDuration(stats.totalTimeMs)} |\n`;
        md += `| **å¼€å§‹æ—¶é—´** | ${stats.startedAt.toLocaleString()} |\n`;
        md += `| **å®Œæˆæ—¶é—´** | ${stats.completedAt.toLocaleString()} |\n`;
        md += `| **æ€»è¯·æ±‚æ¬¡æ•°** | ${stats.totalRequests} æ¬¡ |\n`;
        md += `| **æ€» Token æ¶ˆè€—** | ${stats.totalTokens.toLocaleString()} |\n`;
        md += `| **å¹³å‡é—®é¢˜å¤„ç†æ—¶é—´** | ${this.formatDuration(avgQuestionTime)} |\n`;
        md += `| **æ€»ç»“ç”Ÿæˆæ—¶é—´** | ${this.formatDuration(stats.summaryTimeMs)} |\n`;

        // å„é—®é¢˜è¯¦ç»†æ—¶é—´
        md += `\n### å„é—®é¢˜æ‰§è¡Œæ—¶é—´\n\n`;
        md += `| åºå· | è€—æ—¶ |\n`;
        md += `|------|------|\n`;
        stats.questionTimesMs.forEach((time, index) => {
            md += `| é—®é¢˜ ${index + 1} | ${this.formatDuration(time)} |\n`;
        });

        md += `\n`;
        return md;
    }

    /**
     * ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
     */
    async saveReport(report: ResearchReport): Promise<string> {
        const outputDir = configManager.getConfig().settings.outputDir;
        await fs.mkdir(outputDir, { recursive: true });

        const filename = `${report.task.id}_${new Date()
            .toISOString()
            .slice(0, 10)}.md`;
        const filepath = path.join(outputDir, filename);

        const markdown = this.formatAsMarkdown(report);
        await fs.writeFile(filepath, markdown, "utf-8");

        return filepath;
    }
}

// ============================================================================
// CLI æ¥å£
// ============================================================================

async function main() {
    const args = process.argv.slice(2);

    // è§£æå‚æ•°
    const getArg = (flag: string): string | undefined => {
        const index = args.indexOf(flag);
        return index !== -1 ? args[index + 1] : undefined;
    };

    // åŠ è½½é…ç½®æ–‡ä»¶
    const configPath = getArg("--config");
    const cm = configPath ? new ConfigManager(configPath) : configManager;

    try {
        await cm.load();
    } catch (error) {
        console.error("âŒ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥:", error);
        process.exit(1);
    }

    // æ˜¾ç¤ºé…ç½®
    if (args.includes("--show-config")) {
        cm.displayConfig();
        process.exit(0);
    }

    if (args.length === 0 || args.includes("--help") || args.includes("-h")) {
        console.log(`
ğŸ” Research Assistant Agent
æ™ºèƒ½ç ”ç©¶åŠ©æ‰‹ - ååŠ©è¿›è¡ŒæŠ€æœ¯è°ƒç ”å’Œä¿¡æ¯æ”¶é›†

ä½¿ç”¨æ–¹æ³•:
  npx tsx agents/research-assistant.ts [é€‰é¡¹]

é€‰é¡¹:
  --topic <ä¸»é¢˜>          ç ”ç©¶ä¸»é¢˜ï¼ˆå¿…éœ€ï¼‰
  --questions <é—®é¢˜æ–‡ä»¶>   åŒ…å«ç ”ç©¶é—®é¢˜çš„ JSON æ–‡ä»¶è·¯å¾„
  --depth <æ·±åº¦>          ç ”ç©¶æ·±åº¦: overview | detailed | comprehensive (é»˜è®¤: detailed)
  --format <æ ¼å¼>         è¾“å‡ºæ ¼å¼: summary | report | comparison | decision-matrix (é»˜è®¤: report)
  --provider <æä¾›å•†>     LLM æä¾›å•† (è¦†ç›–é…ç½®æ–‡ä»¶)
  --model <æ¨¡å‹>          æ¨¡å‹åç§° (è¦†ç›–é…ç½®æ–‡ä»¶)
  --config <æ–‡ä»¶>         é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: agents/config/llm-config.json)
  --show-config           æ˜¾ç¤ºå½“å‰é…ç½®
  --save                  ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
  --help, -h              æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯

é…ç½®æ–‡ä»¶:
  é…ç½®æ–‡ä»¶è·¯å¾„: agents/config/llm-config.json

  é…ç½®ç¤ºä¾‹:
  {
    "activeProvider": "glm",
    "providers": {
      "glm": {
        "name": "æ™ºè°± GLM",
        "baseURL": "https://open.bigmodel.cn/api/paas/v4",
        "model": "glm-4",
        "apiKey": "\${GLM_API_KEY}"
      }
    },
    "settings": {
      "maxTokens": 4000,
      "temperature": 0.3,
      "outputDir": "./research-output"
    }
  }

  æ”¯æŒçš„ç¯å¢ƒå˜é‡å¼•ç”¨: \${ENV_VAR_NAME}

ç¤ºä¾‹:
  # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤æä¾›å•†
  npx tsx agents/research-assistant.ts --topic "React 18 æ–°ç‰¹æ€§"

  # ä¸´æ—¶åˆ‡æ¢åˆ°å…¶ä»–æä¾›å•†
  npx tsx agents/research-assistant.ts --topic "å¾®å‰ç«¯æ¶æ„" --provider claude

  # ä½¿ç”¨ç‰¹å®šæ¨¡å‹
  npx tsx agents/research-assistant.ts --topic "AI å‘å±•è¶‹åŠ¿" --provider glm --model glm-4-plus

  # æ˜¾ç¤ºå½“å‰é…ç½®
  npx tsx agents/research-assistant.ts --show-config

  # è¯¦ç»†ç ”ç©¶å¹¶ä¿å­˜
  npx tsx agents/research-assistant.ts --topic "Serverless æ¶æ„" --depth comprehensive --save

é—®é¢˜æ–‡ä»¶æ ¼å¼ (questions.json):
  [
    "GraphQL çš„æ ¸å¿ƒä¼˜åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ",
    "ä¸ REST ç›¸æ¯”æœ‰å“ªäº›æ€§èƒ½å·®å¼‚ï¼Ÿ",
    "åœ¨ä»€ä¹ˆåœºæ™¯ä¸‹åº”è¯¥é€‰æ‹© GraphQLï¼Ÿ"
  ]
    `);
        process.exit(0);
    }

    const topic = getArg("--topic");
    if (!topic) {
        console.error("âŒ é”™è¯¯: è¯·æŒ‡å®šç ”ç©¶ä¸»é¢˜ (--topic)");
        process.exit(1);
    }

    const questionsFile = getArg("--questions");
    let questions: string[] = [];

    if (questionsFile) {
        try {
            const content = await fs.readFile(questionsFile, "utf-8");
            questions = JSON.parse(content);
        } catch (error) {
            console.error(`âŒ æ— æ³•è¯»å–é—®é¢˜æ–‡ä»¶: ${questionsFile}`);
            process.exit(1);
        }
    } else {
        // é»˜è®¤é—®é¢˜
        questions = [
            `${topic} æ˜¯ä»€ä¹ˆï¼Ÿ`,
            `${topic} çš„æ ¸å¿ƒæ¦‚å¿µå’ŒåŸç†æ˜¯ä»€ä¹ˆï¼Ÿ`,
            `${topic} çš„ä¸»è¦ä½¿ç”¨åœºæ™¯æœ‰å“ªäº›ï¼Ÿ`,
            `ä½¿ç”¨ ${topic} çš„æœ€ä½³å®è·µæ˜¯ä»€ä¹ˆï¼Ÿ`,
            `${topic} æœ‰å“ªäº›ä¼˜ç¼ºç‚¹ï¼Ÿ`,
        ];
    }

    const depth = (getArg("--depth") || "detailed") as ResearchTask["depth"];
    const format = (getArg("--format") || "report") as ResearchTask["outputFormat"];
    const shouldSave = args.includes("--save");

    // è·å– LLM é…ç½®
    const provider = getArg("--provider");
    const model = getArg("--model");

    // åˆ›å»ºä»»åŠ¡
    const task: ResearchTask = {
        id: topic.toLowerCase().replace(/\s+/g, "-"),
        topic,
        questions,
        depth,
        outputFormat: format,
    };

    // æ‰§è¡Œç ”ç©¶
    const assistant = new ResearchAssistant(undefined, provider, model);

    try {
        const report = await assistant.conductResearch(task);

        // è¾“å‡ºæŠ¥å‘Š
        console.log("\n" + "=".repeat(60));
        console.log(assistant.formatAsMarkdown(report));

        // è¾“å‡ºæ‰§è¡Œæ€»ç»“åˆ°æ§åˆ¶å°
        if (report.executionStats) {
            const formatDuration = (ms: number): string => {
                if (ms < 1000) {
                    return `${ms}ms`;
                }
                return `${(ms / 1000).toFixed(2)}s`;
            };

            console.log("\n" + "=".repeat(60));
            console.log("ğŸ“Š æ‰§è¡Œæ€»ç»“");
            console.log("=".repeat(60));
            console.log(`â±ï¸  æ€»æ‰§è¡Œæ—¶é—´: ${formatDuration(report.executionStats.totalTimeMs)}`);
            console.log(`ğŸ“ æ€»è¯·æ±‚æ¬¡æ•°: ${report.executionStats.totalRequests} æ¬¡`);
            console.log(`ğŸ”¤ æ€» Token æ¶ˆè€—: ${report.executionStats.totalTokens.toLocaleString()}`);
            console.log(`ğŸ“… å¼€å§‹æ—¶é—´: ${report.executionStats.startedAt.toLocaleString()}`);
            console.log(`âœ… å®Œæˆæ—¶é—´: ${report.executionStats.completedAt.toLocaleString()}`);
            console.log("=".repeat(60));
        }

        // ä¿å­˜æŠ¥å‘Š
        if (shouldSave) {
            const filepath = await assistant.saveReport(report);
            console.log(`\nğŸ’¾ æŠ¥å‘Šå·²ä¿å­˜: ${filepath}`);
        }
    } catch (error) {
        console.error("âŒ ç ”ç©¶è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯:", error);
        process.exit(1);
    }
}

// å¦‚æœç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶ï¼ˆES Module å…¼å®¹å†™æ³•ï¼‰
import { fileURLToPath } from "url";
const __filename = fileURLToPath(import.meta.url);
if (process.argv[1] === __filename) {
    main();
}

// å¯¼å‡ºä¾›å…¶ä»–æ¨¡å—ä½¿ç”¨
export {
    ConfigManager, LLMConfig, ProviderConfig, ResearchFinding,
    ResearchReport, ResearchTask, configManager
};

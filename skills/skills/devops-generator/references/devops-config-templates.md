# DevOpsÈÖçÁΩÆÊ®°Êùø

Êú¨ÊñáÊ°£Êèê‰æõDevOpsÁõ∏ÂÖ≥ÁöÑÈÖçÁΩÆÊ®°ÊùøÔºåÂåÖÊã¨Docker„ÄÅKubernetes„ÄÅCI/CDÂíåÁõëÊéßÈÖçÁΩÆ„ÄÇ

## üê≥ DockerÈÖçÁΩÆÊ®°Êùø

### 1. Â§öÈò∂ÊÆµÊûÑÂª∫Dockerfile

```dockerfile
# ÊûÑÂª∫Èò∂ÊÆµ
FROM node:18-alpine AS builder

# ËÆæÁΩÆÂ∑•‰ΩúÁõÆÂΩï
WORKDIR /app

# Â§çÂà∂packageÊñá‰ª∂
COPY package*.json ./

# ÂÆâË£Ö‰æùËµñ
RUN npm ci --only=production && npm cache clean --force

# Â§çÂà∂Ê∫ê‰ª£Á†Å
COPY . .

# ÊûÑÂª∫Â∫îÁî®
RUN npm run build

# ËøêË°åÈò∂ÊÆµ
FROM node:18-alpine AS runtime

# ËÆæÁΩÆÂ∑•‰ΩúÁõÆÂΩï (ÈáçÂ§ç2)
WORKDIR /app

# ÂàõÂª∫ÈùûrootÁî®Êà∑
RUN addgroup -g 1001 -S nodejs && \
    adduser -S nextjs -u 1001

# Â§çÂà∂packageÊñá‰ª∂ (ÈáçÂ§ç2)
COPY package*.json ./

# Âè™ÂÆâË£ÖÁîü‰∫ß‰æùËµñ
RUN npm ci --only=production && npm cache clean --force

# ‰ªéÊûÑÂª∫Èò∂ÊÆµÂ§çÂà∂ÊûÑÂª∫‰∫ßÁâ©
COPY --from=builder --chown=nextjs:nodejs /app/dist ./dist
COPY --from=builder --chown=nextjs:nodejs /app/node`modules ./node`modules

# ÂàáÊç¢Âà∞ÈùûrootÁî®Êà∑
USER nextjs

# Êö¥Èú≤Á´ØÂè£
EXPOSE 3000

# ÂÅ•Â∫∑Ê£ÄÊü•
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD node healthcheck.js || exit 1

# ÂêØÂä®Â∫îÁî®
CMD ["node", "dist/main.js"]

```

### 2. .dockerignoreÊ®°Êùø

```dockerignore
# Node.js
node_modules
npm-debug.log
yarn-error.log
coverage
.nyc_output

# ÊûÑÂª∫ËæìÂá∫
dist
build
.next
out

# Git
.git
.gitignore
.gitattributes

# Docker
Dockerfile
docker-compose.yml
.dockerignore

# IDE
.vscode
.idea
*.swp
*.swo
*~

# ÁéØÂ¢ÉÂèòÈáè
.env
.env.local
.env.*.local

# ÊµãËØï
test
tests
*.test.js
*.spec.js
*.test.ts
*.spec.ts

# ÊñáÊ°£
README.md
docs
*.md

# ÂÖ∂‰ªñ
.DS_Store
Thumbs.db

```

### 3. docker-compose.ymlÊ®°Êùø

```yaml
version: '3.8'

services:
  # Â∫îÁî®ÊúçÂä°
  app:
    build:
      context: .
      dockerfile: Dockerfile
      target: runtime
    container_name: myapp-app
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://user:password@db:5432/myapp
      - REDIS_URL=redis://redis:6379
    volumes:
      - ./logs:/app/logs
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_started
    networks:
      - app-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "node", "healthcheck.js"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 40s

  # PostgreSQLÊï∞ÊçÆÂ∫ì
  db:
    image: postgres:15-alpine
    container_name: myapp-db
    environment:
      POSTGRES_DB: myapp
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-db:/docker-entrypoint-initdb.d
    ports:
      - "5432:5432"
    networks:
      - app-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user -d myapp"]
      interval: 10s
      timeout: 5s
      retries: 5

  # RedisÁºìÂ≠ò
  redis:
    image: redis:7-alpine
    container_name: myapp-redis
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    networks:
      - app-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  # NginxÂèçÂêë‰ª£ÁêÜ
  nginx:
    image: nginx:alpine
    container_name: myapp-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - app
    networks:
      - app-network
    restart: unless-stopped

  # PrometheusÁõëÊéß
  prometheus:
    image: prom/prometheus:latest
    container_name: myapp-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    networks:
      - app-network
    restart: unless-stopped
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'

  # GrafanaÂèØËßÜÂåñ
  grafana:
    image: grafana/grafana:latest
    container_name: myapp-grafana
    ports:
      - "3001:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    networks:
      - app-network
    restart: unless-stopped
    depends_on:
      - prometheus

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local

networks:
  app-network:
    driver: bridge

```

## ‚ò∏Ô∏è KubernetesÈÖçÁΩÆÊ®°Êùø

### 1. DeploymentÈÖçÁΩÆ

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
  namespace: default
  labels:
    app: myapp
    version: v1.0.0
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
        version: v1.0.0
    spec:
      serviceAccountName: myapp
      containers:
        - name: myapp
          image: myregistry/myapp:latest
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 3000
              protocol: TCP
          env:
            - name: NODE_ENV
              value: "production"
            - name: DATABASE_URL
              valueFrom:
                secretKeyRef:
                  name: myapp-secrets
                  key: database-url
            - name: REDIS_URL
              valueFrom:
                configMapKeyRef:
                  name: myapp-config
                  key: redis-url
            - name: LOG_LEVEL
              valueFrom:
                configMapKeyRef:
                  name: myapp-config
                  key: log-level
          resources:
            requests:
              memory: "256Mi"
              cpu: "250m"
            limits:
              memory: "512Mi"
              cpu: "500m"
          livenessProbe:
            httpGet:
              path: /health
              port: http
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /ready
              port: http
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 5
            timeoutSeconds: 3
            successThreshold: 1
            failureThreshold: 3
          volumeMounts:
            - name: config
              mountPath: /app/config
              readOnly: true
            - name: logs
              mountPath: /app/logs
      volumes:
        - name: config
          configMap:
            name: myapp-config
        - name: logs
          emptyDir: {}
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                labelSelector:
                  matchExpressions:
                    - key: app
                      operator: In
                      values:
                        - myapp
                topologyKey: kubernetes.io/hostname

```

### 2. ServiceÈÖçÁΩÆ

```yaml
apiVersion: v1
kind: Service
metadata:
  name: myapp-service
  namespace: default
  labels:
    app: myapp
spec:
  type: ClusterIP
  selector:
    app: myapp
  ports:
    - name: http
      protocol: TCP
      port: 80
      targetPort: 3000
  sessionAffinity: None

```

### 3. IngressÈÖçÁΩÆ

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: myapp-ingress
  namespace: default
  annotations:
    kubernetes.io/ingress.class: "nginx"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    nginx.ingress.kubernetes.io/proxy-body-size: "50m"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "300"
spec:
  ingressClassName: nginx
  tls:
    - hosts:
        - myapp.example.com
        - api.myapp.example.com
      secretName: myapp-tls
  rules:
    - host: myapp.example.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: myapp-service
                port:
                  number: 80
    - host: api.myapp.example.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: myapp-service
                port:
                  number: 80

```

### 4. ConfigMapÈÖçÁΩÆ

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: myapp-config
  namespace: default
data:
  NODE_ENV: "production"
  PORT: "3000"
  LOG_LEVEL: "info"
  REDIS_URL: "redis://redis:6379"
  DATABASE_POOL_MIN: "2"
  DATABASE_POOL_MAX: "10"
  CACHE_TTL: "300"

```

### 5. SecretÈÖçÁΩÆ

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: myapp-secrets
  namespace: default
type: Opaque
stringData:
  database-url: "postgresql://user:password@postgres:5432/myapp"
  jwt-secret: "your-jwt-secret-key-here"
  api-key: "your-api-key-here"

```

### 6. HPAÈÖçÁΩÆ

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: myapp-hpa
  namespace: default
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myapp
  minReplicas: 3
  maxReplicas: 10
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
        - type: Percent
          value: 50
          periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
        - type: Percent
          value: 100
          periodSeconds: 15
        - type: Pods
          value: 4
          periodSeconds: 15
      selectPolicy: Max

```

### 7. ServiceAccountÈÖçÁΩÆ

```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: myapp
  namespace: default
automountServiceAccountToken: false

```

### 8. PodDisruptionBudgetÈÖçÁΩÆ

```yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: myapp-pdb
  namespace: default
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: myapp

```

## üîÑ CI/CDÈÖçÁΩÆÊ®°Êùø

### 1. GitHub ActionsÈÖçÁΩÆ

```yaml
name: CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

env:
  NODE_VERSION: '18'
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  # ÊµãËØï‰ªªÂä°
  test:
    name: Test
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Lint
        run: npm run lint

      - name: Type check
        run: npm run type-check

      - name: Unit tests
        run: npm run test:unit -- --coverage

      - name: Upload coverage reports
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage/lcov.info
          flags: unittests
          name: codecov-umbrella

  # ÊûÑÂª∫‰ªªÂä°
  build:
    name: Build
    needs: test
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build
        run: npm run build

      - name: Upload build artifacts
        uses: actions/upload-artifact@v3
        with:
          name: build-artifacts
          path: dist/
          retention-days: 7

  # DockerÊûÑÂª∫‰ªªÂä°
  docker-build:
    name: Build and Push Docker Image
    needs: [test, build]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    permissions:
      contents: read
      packages: write
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v2
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v4
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=sha,prefix={{branch}}-

      - name: Build and push Docker image
        uses: docker/build-push-action@v4
        with:
          context: .
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=registry,ref=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:buildcache
          cache-to: type=registry,ref=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:buildcache,mode=max

  # ÈÉ®ÁΩ≤‰ªªÂä°
  deploy:
    name: Deploy to Kubernetes
    needs: docker-build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure kubectl
        uses: azure/k8s-set-context@v3
        with:
          method: kubeconfig
          kubeconfig: ${{ secrets.KUBE_CONFIG }}

      - name: Deploy to Kubernetes
        run: |
          kubectl apply -f k8s/
          kubectl rollout status deployment/myapp

      - name: Verify deployment
        run: |
          kubectl get pods -l app=myapp
          kubectl describe deployment myapp

```

### 2. GitLab CIÈÖçÁΩÆ

```yaml
stages:
  - test
  - build
  - deploy

variables:
  NODE_VERSION: "18"
  REGISTRY: registry.gitlab.com

test:
  stage: test
  image: node:${NODE_VERSION}
  cache:
    paths:
      - node_modules/
  script:
    - npm ci
    - npm run lint
    - npm run type-check
    - npm run test:unit -- --coverage
  coverage: '/All files[^|]`\|[^|]`\s+([\d\.]+)/'
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage/cobertura-coverage.xml

build:
  stage: build
  image: node:${NODE_VERSION}
  cache:
    paths:
      - node_modules/
  script:
    - npm ci
    - npm run build
  artifacts:
    paths:
      - dist/
    expire_in: 1 week
  only:
    - main
    - develop

docker-build:
  stage: build
  image: docker:latest
  services:
    - docker:dind
  variables:
    IMAGE`TAG: $CI`REGISTRY`IMAGE:$CI`COMMIT_SHORT_SHA
  script:
    - echo $CI_REGISTRY`PASSWORD | docker login -u $CI`REGISTRY`USER --password-stdin $CI`REGISTRY
    - docker build -t $IMAGE_TAG .
    - docker push $IMAGE_TAG
  only:
    - main

deploy:production:
  stage: deploy
  image: bitnami/kubectl:latest
  script:
    - kubectl config use-context $KUBE_CONTEXT
    - kubectl apply -f k8s/
    - kubectl rollout restart deployment/myapp
  environment:
    name: production
    url: https://myapp.example.com
  when: manual
  only:
    - main

```

## üìä ÁõëÊéßÈÖçÁΩÆÊ®°Êùø

### 1. PrometheusÈÖçÁΩÆ

```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    cluster: 'myapp-cluster'
    environment: 'production'

alerting:
  alertmanagers:
    - static_configs:
        - targets: ['alertmanager:9093']

rule_files:
  - 'alerts.yml'

scrape_configs:
  # Â∫îÁî®ÁõëÊéß
  - job_name: 'myapp'
    metrics_path: '/metrics'
    scrape_interval: 10s
    static_configs:
      - targets: ['myapp-service:3000']
        labels:
          app: 'myapp'
          environment: 'production'

  # PostgreSQLÁõëÊéß
  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']
        labels:
          db: 'postgres'

  # RedisÁõëÊéß
  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']
        labels:
          db: 'redis'

  # KubernetesËäÇÁÇπÁõëÊéß
  - job_name: 'kubernetes-nodes'
    scheme: https
    tls_config:
      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    kubernetes_sd_configs:
      - role: node
    relabel_configs:
      - source`labels: [`_address__]
        regex: '(.*):10250'
        target`label: `_address__
        replacement: '${1}:9100'

  # Kubernetes PodsÁõëÊéß
  - job_name: 'kubernetes-pods'
    kubernetes_sd_configs:
      - role: pod
    relabel_configs:
      - source`labels: [`_meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source`labels: [`_meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target`label: `_metrics_path__
        regex: (.+)
      - source`labels: [`_address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        target`label: `_address__

```

### 2. PrometheusÂëäË≠¶ËßÑÂàô

```yaml
groups:
  - name: myapp_alerts
    interval: 30s
    rules:
      # Â∫îÁî®ÂÆïÊú∫
      - alert: MyAppDown
        expr: up{job="myapp"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "MyAppÂÆû‰æãÂÆïÊú∫"
          description: "MyAppÂÆû‰æã {{ $labels.instance }} Â∑≤ÁªèÂÆïÊú∫Ë∂ÖËøá1ÂàÜÈíü"

      # È´òÈîôËØØÁéá
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "È´òÈîôËØØÁéá"
          description: "ÈîôËØØÁéáË∂ÖËøá10%: {{ $value }} errors/sec"

      # È´òÂª∂Ëøü
      - alert: HighLatency
        expr: histogram`quantile(0.95, http`request_duration_seconds_bucket) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "È´òÂª∂Ëøü"
          description: "P95Âª∂ËøüË∂ÖËøá1Áßí: {{ $value }}s"

      # È´òÂÜÖÂ≠ò‰ΩøÁî®
      - alert: HighMemoryUsage
        expr: (container_memory_usage`bytes / container`spec_memory_limit_bytes) > 0.9
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "È´òÂÜÖÂ≠ò‰ΩøÁî®"
          description: "ÂÆπÂô®ÂÜÖÂ≠ò‰ΩøÁî®Ë∂ÖËøá90%: {{ $value }}%"

      # È´òCPU‰ΩøÁî®
      - alert: HighCPUUsage
        expr: rate(container_cpu_usage_seconds_total[5m]) > 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "È´òCPU‰ΩøÁî®"
          description: "ÂÆπÂô®CPU‰ΩøÁî®Ë∂ÖËøá80%: {{ $value }}"

      # Êï∞ÊçÆÂ∫ìËøûÊé•Ê±†ËÄóÂ∞Ω
      - alert: DatabaseConnectionPoolExhausted
        expr: pg_stat_activity`count / pg`settings_max_connections > 0.9
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Êï∞ÊçÆÂ∫ìËøûÊé•Ê±†ËÄóÂ∞Ω"
          description: "Êï∞ÊçÆÂ∫ìËøûÊé•Ê±†‰ΩøÁî®Ë∂ÖËøá90%: {{ $value }}%"

```

### 3. Grafana DashboardÈÖçÁΩÆ

```json
{
  "dashboard": {
    "title": "My Application Dashboard",
    "tags": ["myapp"],
    "timezone": "browser",
    "refresh": "30s",
    "panels": [
      {
        "id": 1,
        "title": "Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{status}}"
          }
        ],
        "yaxes": [
          {
            "format": "reqps"
          }
        ]
      },
      {
        "id": 2,
        "title": "Error Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total{status=~\"5..\"}[5m])",
            "legendFormat": "Server Errors"
          }
        ],
        "yaxes": [
          {
            "format": "reqps"
          }
        ]
      },
      {
        "id": 3,
        "title": "Response Time",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram`quantile(0.95, http`request_duration_seconds_bucket)",
            "legendFormat": "95th Percentile"
          },
          {
            "expr": "histogram`quantile(0.99, http`request_duration_seconds_bucket)",
            "legendFormat": "99th Percentile"
          }
        ],
        "yaxes": [
          {
            "format": "s"
          }
        ]
      },
      {
        "id": 4,
        "title": "CPU Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(container_cpu_usage_seconds_total{container=\"myapp\"}[5m]) * 100",
            "legendFormat": "CPU"
          }
        ],
        "yaxes": [
          {
            "format": "percent"
          }
        ]
      },
      {
        "id": 5,
        "title": "Memory Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "container_memory_usage_bytes{container=\"myapp\"} / 1024 / 1024",
            "legendFormat": "Memory"
          }
        ],
        "yaxes": [
          {
            "format": "decmbytes"
          }
        ]
      },
      {
        "id": 6,
        "title": "Active Connections",
        "type": "graph",
        "targets": [
          {
            "expr": "pg_stat_activity_count",
            "legendFormat": "Connections"
          }
        ],
        "yaxes": [
          {
            "format": "short"
          }
        ]
      }
    ]
  }
}

```

## üîê ÂÆâÂÖ®ÈÖçÁΩÆÊ®°Êùø

### 1. NetworkPolicyÈÖçÁΩÆ

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: myapp-network-policy
  namespace: default
spec:
  podSelector:
    matchLabels:
      app: myapp
  policyTypes:
    - Ingress
    - Egress
  ingress:
    - from:
        - namespaceSelector:
            matchLabels:
              name: ingress-nginx
      ports:
        - protocol: TCP
          port: 3000
    - from:
        - podSelector:
            matchLabels:
              app: prometheus
      ports:
        - protocol: TCP
          port: 3000
  egress:
    - to:
        - podSelector:
            matchLabels:
              app: postgres
      ports:
        - protocol: TCP
          port: 5432
    - to:
        - podSelector:
            matchLabels:
              app: redis
      ports:
        - protocol: TCP
          port: 6379

```

### 2. PodSecurityPolicyÈÖçÁΩÆ

```yaml
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: myapp-psp
  annotations:
    seccomp.security.alpha.kubernetes.io/allowedProfiles: 'runtime/default'
spec:
  privileged: false
  allowPrivilegeEscalation: false
  requiredDropCapabilities:
    - ALL
  volumes:
    - 'configMap'
    - 'emptyDir'
    - 'projected'
    - 'secret'
    - 'downwardAPI'
    - 'persistentVolumeClaim'
  hostNetwork: false
  hostIPC: false
  hostPID: false
  runAsUser:
    rule: 'MustRunAsNonRoot'
  seLinux:
    rule: 'RunAsAny'
  fsGroup:
    rule: 'RunAsAny'
  supplementalGroups:
    rule: 'RunAsAny'
  readOnlyRootFilesystem: false

```
